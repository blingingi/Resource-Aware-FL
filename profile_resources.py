#!/usr/bin/env python
# -*- coding: utf-8 -*-

import numpy as np
from torchvision import datasets, transforms
from utils.sampling import cifar_dirichlet
from utils.resource import ResourceManager

def profile_system_resources():
    print("="*50)
    print("ğŸš€ å¯åŠ¨ç³»ç»Ÿèµ„æºæ‘¸åº•æµ‹è¯• (CIFAR-10, Dir=0.1)")
    print("="*50)

    # 1. æ¨¡æ‹Ÿå‚æ•°
    num_users = 100
    alpha = 0.1
    local_bs = 32
    
    # 2. åŠ è½½æ•°æ®é›†
    print("åŠ è½½ CIFAR-10 æ•°æ®é›†...")
    trans_train = transforms.Compose([
        transforms.RandomCrop(32, padding=4),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])
    dataset_train = datasets.CIFAR10('../data/cifar', train=True, download=True, transform=trans_train)

    # 3. åˆ’åˆ†æ•°æ® (ä¸¥æ ¼ä½¿ç”¨ä½ åˆšåˆšä¿®å¥½çš„å¸¦ min_require_size çš„é‡‡æ ·å‡½æ•°)
    print(f"æŒ‰ Dirichlet (alpha={alpha}) åˆ’åˆ†æ•°æ®ä¸­...")
    dict_users = cifar_dirichlet(dataset_train, num_users, alpha, local_bs)
    
    # 4. åˆå§‹åŒ–èµ„æºç®¡ç†å™¨
    resource_mgr = ResourceManager(num_users)
    
    # 5. è®¡ç®—å¹¶æ”¶é›†æ‰€æœ‰å®¢æˆ·ç«¯çš„èµ„æºå¼€é”€
    times = []
    energies = []
    data_sizes = []
    
    for i in range(num_users):
        data_size = len(dict_users[i])
        # å‡è®¾ local_ep = 2
        # æ³¨æ„ï¼šå¦‚æœä½ çš„ resource_mgr.calculate_cost æ²¡æœ‰è€ƒè™‘ epochï¼Œé‚£è¿™é‡Œçš„æˆæœ¬å°±æ˜¯å•è½®æˆæœ¬ã€‚
        # è¿™é‡Œæˆ‘ä»¬ç›´æ¥é€è§†å®ƒè¿”å›çš„å€¼
        t, e = resource_mgr.calculate_cost(i, data_size)
        times.append(t)
        energies.append(e)
        data_sizes.append(data_size)

    # 6. ç»Ÿè®¡åˆ†æ
    times = np.array(times)
    energies = np.array(energies)
    data_sizes = np.array(data_sizes)
    
    print("\nğŸ“Š --- [æ•°æ®é‡åˆ†å¸ƒ] ---")
    print(f"æœ€å°æ•°æ®é‡: {data_sizes.min()} å¼ ")
    print(f"æœ€å¤§æ•°æ®é‡: {data_sizes.max()} å¼ ")
    print(f"å¹³å‡æ•°æ®é‡: {data_sizes.mean():.1f} å¼ ")
    
    print("\nâ±ï¸ --- [æ—¶å»¶ (Latency) åˆ†å¸ƒ] ---")
    print(f"æœ€å¿«å®Œæˆ: {times.min():.2f} s")
    print(f"æœ€æ…¢å®Œæˆ: {times.max():.2f} s")
    print(f"å¹³å‡è€—æ—¶: {times.mean():.2f} s")
    print(f"ä¸­ä½æ•° (50%çš„äººå°äº): {np.median(times):.2f} s")
    print(f"75% åˆ†ä½æ•° (75%çš„äººå°äº): {np.percentile(times, 75):.2f} s")
    print(f"90% åˆ†ä½æ•° (90%çš„äººå°äº): {np.percentile(times, 90):.2f} s")

    print("\nğŸ”‹ --- [å•å®¢æˆ·ç«¯èƒ½è€— (Energy) åˆ†å¸ƒ] ---")
    print(f"æœ€ä½èƒ½è€—: {energies.min():.2f} J")
    print(f"æœ€é«˜èƒ½è€—: {energies.max():.2f} J")
    print(f"å¹³å‡èƒ½è€—: {energies.mean():.2f} J")
    
    print("\nğŸ’¡ --- [å…³äº max_energy çš„è®¾å®šå»ºè®®] ---")
    # å‡è®¾æˆ‘ä»¬ä¸€è½®é€‰ 10 ä¸ªäºº (frac=0.1)
    avg_round_energy = energies.mean() * 10
    print(f"å¦‚æœéšæœºé€‰ 10 ä¸ªäººï¼Œä¸€è½®çš„å¹³å‡æ€»èƒ½è€—çº¦ä¸º: {avg_round_energy:.2f} J")
    
    print("\nğŸ¯ --- [å­¦é•¿çš„ç»ˆæè®¾å®šå»ºè®®] ---")
    print("1. ã€æŒ‘æˆ˜æ€§ max_timeã€‘: å»ºè®®è®¾åœ¨ 'ä¸­ä½æ•°' å’Œ '75% åˆ†ä½æ•°' ä¹‹é—´ã€‚")
    print("   è¿™ä¼šé€¼è¿«ä½ çš„ Ours ç®—æ³•å¯¹é‚£ 25% æœ€æ…¢çš„èŠ‚ç‚¹ä½¿ç”¨'å¼¹æ€§é™çº§(Partial Work)'ã€‚")
    print(f"2. ã€æŒ‘æˆ˜æ€§ max_energyã€‘: å»ºè®®è®¾ä¸ºå¹³å‡æ€»èƒ½è€— ({avg_round_energy:.2f} J) çš„ 70% ~ 80%ã€‚")
    print("   è¿™ä¼šé€¼è¿«ä½ çš„è´ªå¿ƒèƒŒåŒ…ç®—æ³•ç²¾æ‰“ç»†ç®—ï¼Œç»ä¸æµªè´¹å“ªæ€• 1 ç„¦è€³çš„ç”µé‡ï¼")
    print("="*50)

if __name__ == '__main__':
    profile_system_resources()